# Dataset metadata
dataset:
    key: common-voice
    labels:
        - bre
        - est
        - mon
        - tur

# How often to print progress, for operations that take a long time
print_progress: 25

# Feature extraction
features:
    # Before extracting features, resample the file to this freq regardless of the native rate
    resample_to: 16000
    # Try to remove silence from all files before starting feature extraction
    apply_vad: True
    # Split all files into 3 second chunks
    utterance_length_ms: 3000
    # Use 0.5 second offset when extracting utterances, i.e. every utterance will share 2.5 seconds with the previous and next utterances
    utterance_offset_ms: 500
    # Length of time-dependent input sequences for the LSTM layers
    sequence_length: 16
    # Extract 20 MFCCs using librosa
    extractors:
        - name: mfcc
          kwargs:
              n_mfcc: 20

# Training and model hyperparameters
experiment:
    # For naming directories etc, has no inherent meaning
    name: lstm_1_layer_512_cells
    # Which Keras model module to load from speechbox.models
    model_definition:
        # Single layer LSTM, nothing fancy
        name: lstm
        kwargs:
            num_layers: 1
            num_cells: 512
    optimizer:
        cls: Adam
    loss: categorical_crossentropy
    metrics:
        - accuracy
        - precision
        - recall
    batch_size: 4
    epochs: 20
    # How many batches per epoch
    steps_per_epoch: 500
    validation_steps: 50
    # Size of shuffle buffer containing samples
    dataset_shuffle_size: 10000
    # Always use CPU for evaluation
    eval_device: "/CPU:0"
