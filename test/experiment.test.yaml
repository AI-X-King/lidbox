# Dataset metadata
dataset:
    key: common-voice
    labels:
        - bre
        - est
        - mon
        - tur

# How often to print progress, for operations that take a long time
print_progress: 25

# Feature extraction
features:
    # Augment the training and validation sets by creating new audio files from speed and volume transformations
    augmentation:
        datagroups:
            - training
            - validation
        # Use only augmented files for training and validation
        ignore_src_files: True
        # Create 9 different combinations of all pairs
        cartesian_product:
            volume: [0.25, 1.0, 2.0]
            speed: [0.9, 1.0, 1.1]
    # Before extracting features, resample the file to this freq regardless of the native rate
    resample_to: 16000
    # Try to remove silence from all files before starting feature extraction
    apply_vad: True
    # Slide a 2 second window over all audio files of each label to produce utterances
    # By default, audio file boundaries are ignored
    utterance_length_ms: 2000
    # Use 0.5 second offset when extracting utterances, i.e. every utterance will share 1.5 seconds with the previous and next utterances
    utterance_offset_ms: 500
    # Length of time-dependent input sequences for the LSTM layers
    sequence_length: 16
    # Extract 20 MFCCs using librosa
    extractors:
        - name: mfcc
          kwargs:
              n_mfcc: 20

# Training and model hyperparameters
experiment:
    # For naming directories etc, has no inherent meaning
    name: lstm_3_layer_512_cells
    # Which Keras model module to load from speechbox.models
    model_definition:
        # 3-layer LSTM with 512, 256, and 128 cells (ordered from input to output)
        name: lstm
        kwargs:
            num_cells: 512
            num_layers: 3
            # Cut num_cells in half after each layer
            narrowing: True
    optimizer:
        cls: Adam
        kwargs:
            learning_rate: 0.0001
    loss: categorical_crossentropy
    metrics:
        - accuracy
        - precision
        - recall
    batch_size: 16
    epochs: 20
    # Repeat samples from each label indefinitely
    repeat: -1
    # How many batches per epoch for training and validation
    steps_per_epoch: 500
    validation_steps: 50
    # How many samples to draw from the dataset iterator into the shuffle buffer,
    # from which we then draw samples uniformly at random used to train the model
    dataset_shuffle_size: 10000

evaluation:
    features:
        apply_vad: True
        utterance_length_ms: 10000
        utterance_offset_ms: 5000
    metrics:
        - accuracy
        - precision
        - recall
