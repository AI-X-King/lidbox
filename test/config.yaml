# Directory for experiment state and all generated output
cache: ./test-cache

# Dataset metadata
dataset:
    key: common-voice
    src: /m/data/common-voice
    labels:
        - est
        - mon
        - nld
        - tur

# How often to print progress, for operations that take a long time
print_progress: 1000

# Augment the training set by creating new audio files from speed and volume transformations
augmentation:
    datagroups:
        - training
    list:
        - speed: 0.9
        - speed: 1.1

# Feature extraction
features:
    datagroups:
        - training
        - validation
    # Try to remove silence from all files before starting feature extraction
    apply_vad: True
    # Slide a 4 second window over all audio files of each label to produce utterances
    # By default, audio file boundaries are ignored
    utterance_length_ms: 4000
    # Use 2 second offset when extracting utterances, i.e. all consecutive utterances will overlap by 50%
    utterance_offset_ms: 2000
    # Slide 4 second window over each utterance separately, instead of creating one large utterance by concatenating all utterances
    slide_over_all: False
    # Length of time-dependent input sequences for the RNN model
    sequence_length: 32
    # Use librosa to extract 20 MFCCs and concatenate them with their deltas and delta-deltas
    # This yields feature vectors with 60 elements for every window
    extractors:
        - name: mfcc-deltas-012
          kwargs:
              n_mfcc: 20
              n_fft: 1024
              hop_length: 128
              fmin: 50
              fmax: 7000
              n_mels: 40
              power: 2.5

# Training and model hyperparameters
experiment:
    # For naming directories etc, has no inherent meaning
    name: blstm_2_layer
    # Which Keras model module to load from speechbox.models
    model_definition:
        # 2-layer BLSTM with 200 and 100 units
        name: blstm
        kwargs:
            num_cells: 100
            num_layers: 2
            # Cut num_cells in half after each layer
            narrowing: True
    optimizer:
        cls: Adam
        kwargs:
            learning_rate: 0.0002
    loss: categorical_crossentropy
    metrics:
        - accuracy
    batch_size: 8
    epochs: 2000
    # Repeat samples from each label indefinitely
    repeat: -1
    # How many batches per epoch for training and validation
    steps_per_epoch: 5000
    validation_steps: 500
    # How many samples to draw from the dataset iterator into the shuffle buffer,
    # from which we then draw samples uniformly at random used to train the model
    dataset_shuffle_size: 50000
    # Save checkpoints every time we get the highest validation accuracy
    checkpoints:
        save_best_only: True
        monitor: val_accuracy
        format: "epoch{epoch:06d}__val_loss{val_loss:.12f}__val_accuracy{val_accuracy:.3f}.hdf5"
